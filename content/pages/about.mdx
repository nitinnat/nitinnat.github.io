---
title: "About"
---

# About Me

I build production GenAI systems at o9 Solutions. Currently focused on agentic workflows with LLMs, RAG architectures, document ingestion pipelines, and the infrastructure that makes these systems work at scale. I work on interesting problems in the GenAI engineering layer - effective API design, context and memory management for long conversations, making non-deterministic systems debuggable, prompt design, agent behavior evaluation in production, hierarchical memory systems, and making LLM applications observable.

Before GenAI, I spent years building AutoML systems for time series forecasting at retail scale, processing terabytes of data for 10,000+ locations using PySpark and Hadoop for distributed training. Worked on the full ML infrastructure stack: big data pipelines, model serving APIs, monitoring systems, hyperparameter optimization, automated retraining. Earlier in grad school, I did research in computer vision (unsupervised cursor tracking with Adobe Research) and federated learning (distributed SVM training without centralizing data). I have an MS in Computer Science from the University at Buffalo, where I specialized in computer vision and distributed machine learning.

---

## Professional Timeline

### Senior Software Engineer, GenAI
**o9 Solutions** 路 *April 2025 - Present*

![GenAI Agentic Workflow](/assets/genai_workflow.png)

*Illustrative diagram only; does not reflect actual implementation.*

Building production agentic workflows that combine tool use, retrieval-augmented generation, and persistent memory. Work involves designing multi-agent orchestration patterns, implementing context management strategies for long-running conversations, building evaluation frameworks for non-deterministic systems, and designing document ingestion pipelines for RAG. Focus on API design and making LLM applications debuggable, robust and observable in production environments.

---

### Software Engineer II, Machine Learning
**o9 Solutions** 路 *April 2022 - April 2025*

![AutoML Time Series Forecasting](/assets/automl_forecasting.png)

*Illustrative diagram only; does not reflect actual implementation.*

Built AutoML pipelines for time series forecasting at retail scale. Designed distributed training infrastructure on Kubernetes, processing historical sales data for 10,000+ store locations using PySpark and TensorFlow. Implemented hyperparameter optimization strategies, model selection frameworks, and automated retraining pipelines. Later transitioned to LLM-based conversational systems, building prompt engineering frameworks and retrieval pipelines before the tooling ecosystem matured.

[Read case study](https://o9solutions.com/case-studies/coffee-corporation/)

---

### Software Engineer, Machine Learning
**o9 Solutions** 路 *August 2019 - April 2022*

Built infrastructure for ML platform reliability and scalability. Designed REST APIs for model serving, implemented horizontal scaling strategies, and built monitoring systems for production ML pipelines. Integrated JupyterHub with custom authentication plugins and resource management for data science workflows. Established CI/CD patterns for ML deployments, bridging the gap between research notebooks and production services.

---

### Graduate Research Assistant
**University at Buffalo** 路 *September 2018 - May 2019*

![Cursor Tracking System](/assets/cursor_tracking.png)

Collaborated with Adobe Research on cursor detection and tracking in screen recording videos. Built an unsupervised approach combining adaptive template discovery, multi-scale matching, and optimal path algorithms. The method outperformed supervised baselines like Faster-RCNN and online trackers (TLD, CSRT, MIL) without requiring labeled training data. Interesting problem: cursor appearance varies wildly across systems, making supervised learning brittle.

---

### Student Research Assistant
**University at Buffalo** 路 *September 2017 - November 2018*

![Federated Learning System](/assets/federated_learning.png)

Worked with Prof. Haimonti Dutta on federated learning before it was called that. Built GADGET, a gossip-based distributed SVM solver that trains models across nodes without centralizing data. Each node only shares gradient information with neighbors, converging to the global solution through iterative communication. Also worked on NLP problems: named entity recognition and detecting inter-group prejudice patterns in social media text.

---

### Applied Machine Learning Intern
**Clarifai** 路 *May 2018 - August 2018*

![Object Tracking System](/assets/clarifai_tracking.png)

Built hybrid object tracking systems that combine detection and tracking to reduce drift in long videos. Analyzed temporal noise characteristics of industrial depth cameras to improve computer vision pipelines. Extended internal visualization tools for video annotation and model debugging. Short internship, but got hands-on with production CV systems at a company doing visual recognition at scale.

---

### Software Engineer
**Fidelity Investments** 路 *June 2015 - June 2017*

![Chatbot System](/assets/fidelity_chatbot.png)

Built QBot, an enterprise chatbot before transformer models existed. Used ontology-based intent matching, word2vec embeddings, and rule-based dialogue management. Also developed sentiment analysis systems using topic modeling (LDA) and text classification, hitting 93%+ cross-validation accuracy on internal support tickets. Deployed everything in Docker containers. This was pre-BERT, pre-GPT.

Started as an analytics trainee managing metrics for distributed teams of 120+ people. Wrote complex SQL queries pulling data from multiple sources, built Tableau dashboards for KPI tracking and operational metrics. Administered Tableau Server and managed user permissions. First exposure to working with data at scale.

---

### Summer Research Intern (Computer Vision)
**Indian Institute of Science** 路 *May 2014 - July 2014*

Undergraduate research on feature extraction for optical character recognition with Dr. Rathna G.N. Compared PCA, Local Binary Patterns, and other classical computer vision techniques. Built a MATLAB GUI to demonstrate real-time OCR. Early exposure to computer vision and pattern recognition, before my formal training in CS.

---

## Education

**University at Buffalo**
Master of Science in Computer Science 路 *2017 - 2019*

**National Institute of Technology Karnataka**
Bachelor of Technology in Electrical and Electronics Engineering 路 *2011 - 2015*

---

## Publications

### Mouse Cursor Detection and Tracking in Instructional Videos
**Nataraj, N., Zhou, C., & Yuan, J.** (2019). *Technical Report, University at Buffalo*. [Submitted to WACV 2019]

[ Download PDF](/assets/papers/cursor_tracking.pdf)

![Cursor Detection and Tracking](/assets/cursor_tracking.png)

**Abstract:** Many expert users of particular software, e.g. Adobe Photoshop regularly post instructional videos online, imparting knowledge on how to perform certain tasks. An important feature that can be used to understand the instructor's actions in an instructional video, is to detect and track the mouse cursor throughout the entirety of each video. Despite recent progress of object detection and tracking, identifying the mouse cursor in such videos is a unique and difficult problem since the mouse cursor typically occupies a very small percentage of the entire frame (0.05-1%), exhibits fast movement, and is prone to instant appearance changes and background clutter. We propose a novel three-step tracking-by-detection approach for mouse cursor detection and tracking: unsupervised cursor discovery, multi-scale template matching, and optimal spatiotemporal path search. Our approach is completely unsupervised and is able to handle instant appearance changes and fast movements of the mouse cursor. We present evaluations on a dataset of annotated Adobe Photoshop instructional videos, and show that our method beats conventional online tracking methods such as TLD, MIL and CSRT trackers by a large margin. For a more fair comparison, we also compare our results with Faster-RCNN, a deep learning based object detector, and show comparable success rates.

---

### Consensus Based Vertically Partitioned Multi-layer Perceptrons for Edge Computing
**Dutta, H., Mahindre, S., & Nataraj, N.** (2021). *Proceedings of the 20th IEEE International Conference on Machine Learning and Applications (ICMLA)*.

[ View Paper](https://link.springer.com/chapter/10.1007/978-3-030-88942-5_20)

![Consensus Based Vertically Partitioned MLPs](/assets/consensus_mlp_vertical.png)

**Abstract:** Storing large volumes of data on distributed devices has become commonplace in recent years. Applications involving sensors capture data in different modalities including image, video, audio, GPS and others. Novel distributed algorithms are required to learn from this rich, multi-modal data. We present an algorithm for learning consensus based multi-layer perceptrons on resource-constrained devices. Assuming nodes (devices) in the distributed system are arranged in a graph and contain vertically partitioned data and labels, the goal is to learn a global function that minimizes the loss. Each node learns a feed-forward multi-layer perceptron and obtains a loss on data stored locally. It then gossips with a neighbor, chosen uniformly at random, and exchanges information about the loss. The updated loss is used to run a back propagation algorithm and adjust local weights appropriately. This method enables nodes to learn the global function without exchange of data in the network. Empirical results reveal that the consensus algorithm converges to the centralized model and has performance comparable to centralized multi-layer perceptrons and tree-based algorithms.

---

### Consensus Based Multi-Layer Perceptrons for Edge Computing
**Dutta, H., Nataraj, N., & Mahindre, S.** (2021). *arXiv preprint*.

[ View on arXiv](https://arxiv.org/abs/2102.05021)

![Consensus Based MLPs for Edge Computing](/assets/consensus_mlp_edge.png)

**Abstract:** In recent years, storing large volumes of data on distributed devices has become commonplace. Applications involving sensors capture data in different modalities including image, video, audio, GPS and others. Novel algorithms are required to learn from this rich distributed data. We present consensus based multi-layer perceptrons for resource-constrained devices. Assuming nodes (devices) in the distributed system are arranged in a graph and contain vertically partitioned data, the goal is to learn a global function that minimizes the loss. Each node learns a feed-forward multi-layer perceptron and obtains a loss on data stored locally. It then gossips with a neighbor, chosen uniformly at random, and exchanges information about the loss. The updated loss is used to run a back propagation algorithm and adjust weights appropriately. This method enables nodes to learn the global function without exchange of data in the network.

---

### GADGET SVM: A Gossip-bAseD sub-GradiEnT Solver for Linear SVMs
**Dutta, H., & Nataraj, N.** (2018). *arXiv preprint*.

[ View on arXiv](https://arxiv.org/abs/1812.02261)

![Federated Learning System](/assets/federated_learning.png)

**Abstract:** In the era of big data, an important weapon in a machine learning researcher's arsenal is a scalable Support Vector Machine (SVM) algorithm. SVMs are extensively used for solving classification problems. Traditional algorithms for learning SVMs often scale super linearly with training set size which becomes infeasible very quickly for large data sets. In recent years, scalable algorithms have been designed which study the primal or dual formulations of the problem. This often suggests a way to decompose the problem and facilitate development of distributed algorithms. We present a distributed algorithm for learning linear Support Vector Machines in the primal form for binary classification called Gossip-bAseD sub-GradiEnT (GADGET) SVM. The algorithm is designed such that it can be executed locally on nodes of a distributed system. Each node processes its local homogeneously partitioned data and learns a primal SVM model. It then gossips with random neighbors about the classifier learnt and uses this information to update the model. Extensive theoretical and empirical results suggest that this anytime algorithm has performance comparable to its centralized and online counterparts.

---
